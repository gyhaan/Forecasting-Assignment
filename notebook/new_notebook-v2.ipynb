{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3a214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported - Enhanced for Experiment 7!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries - added for attention and GRU\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, Bidirectional, Input, Layer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2  # IMPROVEMENT: Add L2 regularization\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # IMPROVEMENT: More metrics\n",
    "from sklearn.model_selection import TimeSeriesSplit  # IMPROVEMENT: For better validation\n",
    "\n",
    "# Custom Attention Layer\n",
    "class SimpleAttention(Layer):\n",
    "    def __init__(self):\n",
    "        super(SimpleAttention, self).__init__()\n",
    "        self.dense = Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attention_weights = tf.nn.softmax(self.dense(inputs), axis=1)\n",
    "        return tf.reduce_sum(inputs * attention_weights, axis=1)\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('default')\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported - Enhanced for Experiment 7!\")\n",
    "\n",
    "# Submission system remains the same\n",
    "def save_submission(predictions, experiment_name, test_index, notes=\"\"):\n",
    "    os.makedirs('submissions', exist_ok=True)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'row ID': test_index.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'pm2.5': np.round(predictions).astype(int)\n",
    "    })\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f'submissions/{timestamp}_{experiment_name}.csv'\n",
    "    \n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Submission saved: {filename}\")\n",
    "    print(f\"üìä Predictions - Min: {predictions.min():.1f}, Max: {predictions.max():.1f}, Mean: {predictions.mean():.1f}\")\n",
    "    print(f\"üìù Notes: {notes}\")\n",
    "    \n",
    "    return filename, submission\n",
    "\n",
    "print(\"‚úÖ Submission system ready - targeting <3400 RMSE!\")\n",
    "\n",
    "# Data loading remains the same\n",
    "print(\"üìÇ Loading datasets...\")\n",
    "train = pd.read_csv('../data/train.csv')\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "train['datetime'] = pd.to_datetime(train['datetime'])\n",
    "test['datetime'] = pd.to_datetime(test['datetime'])\n",
    "\n",
    "train.set_index('datetime', inplace=True)\n",
    "test.set_index('datetime', inplace=True)\n",
    "\n",
    "print(\"üîß Handling missing values...\")\n",
    "train_clean = train.fillna(method='ffill').fillna(method='bfill').interpolate()\n",
    "test_clean = test.fillna(method='ffill').fillna(method='bfill').interpolate()\n",
    "\n",
    "# IMPROVED feature engineering - Add EMAs and more interactions\n",
    "def create_enhanced_features(df, target_col='pm2.5'):\n",
    "    df_enhanced = create_focused_features(df, target_col)  # Start with Notebook 6 features\n",
    "    \n",
    "    print(\"üîß Adding advanced features (Experiment 7)...\")\n",
    "    # IMPROVEMENT: Exponential Moving Averages for smoother trends\n",
    "    if target_col in df_enhanced.columns:\n",
    "        for span in [12, 24, 48]:\n",
    "            df_enhanced[f'pm2.5_ema_{span}'] = df_enhanced[target_col].ewm(span=span).mean()\n",
    "    \n",
    "    # IMPROVEMENT: More weather interactions\n",
    "    df_enhanced['temp_humidity_interact'] = df_enhanced['TEMP'] * df_enhanced['humidity_proxy']\n",
    "    df_enhanced['wind_temp_interact'] = df_enhanced['Iws'] * df_enhanced['TEMP']\n",
    "    \n",
    "    # Drop any new NaNs\n",
    "    df_enhanced = df_enhanced.fillna(method='bfill').fillna(0)\n",
    "    \n",
    "    return df_enhanced\n",
    "\n",
    "def create_test_features_enhanced(df):\n",
    "    return create_enhanced_features(df).drop([col for col in df.columns if 'pm2.5' in col], axis=1, errors='ignore')\n",
    "\n",
    "# Apply\n",
    "train_enhanced = create_enhanced_features(train_clean)\n",
    "test_enhanced = create_test_features_enhanced(test_clean)\n",
    "\n",
    "# Feature alignment (now ~45 features)\n",
    "common_features = [col for col in train_enhanced.columns if col in test_enhanced.columns and col not in ['pm2.5', 'No']]\n",
    "X_train_common = train_enhanced[common_features]\n",
    "y_train = train_enhanced['pm2.5']\n",
    "X_test_common = test_enhanced[common_features]\n",
    "\n",
    "print(f\"üìä Enhanced features: {len(common_features)} (added EMAs + interactions)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b046e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856724d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
